{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e735e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/celiasagastume/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e10f38c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './jigsaw-toxic-severity-rating/validation_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/84/d8w_w6jd1fx_sdq6fsd408cc0000gn/T/ipykernel_77998/1434189218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./jigsaw-toxic-severity-rating/validation_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './jigsaw-toxic-severity-rating/validation_data.csv'"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data = pd.read_csv(\"./jigsaw-toxic-severity-rating/validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ec304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create distinct df's for more toxic and less toxic comments\n",
    "\n",
    "less_toxic = data.drop('more_toxic', axis=1)\n",
    "more_toxic = data.drop('less_toxic', axis =1)\n",
    "\n",
    "#add target column to both \n",
    "\n",
    "less_toxic['target'] = 0\n",
    "more_toxic['target'] = 1\n",
    "\n",
    "#rename text column for both \n",
    "\n",
    "less_toxic = less_toxic.rename(columns={'less_toxic':'text'})\n",
    "more_toxic = more_toxic.rename(columns={'more_toxic':'text'})\n",
    "\n",
    "#rejoin data \n",
    "\n",
    "comments = pd.concat([less_toxic, more_toxic], axis =0)\n",
    "\n",
    "#randomly reorder\n",
    "\n",
    "comments = comments.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#create average target score for comments \n",
    "comments = comments.groupby('text')['target'].mean().reset_index()\n",
    "\n",
    "#shape\n",
    "print(comments.head())\n",
    "\n",
    "#save comments\n",
    "\n",
    "comments.to_csv(\"comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13102823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #remap target values \n",
    "\n",
    "comments['target'] = (comments['target'] > 0.0) * 1\n",
    "\n",
    "#histogram of toxic values per comment \n",
    "%matplotlib inline\n",
    "sns.histplot(data=comments, x=\"target\", binwidth=.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31949202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create text clean + tokenizer function\n",
    "\n",
    "punc = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~__'\n",
    "words = set(nltk.corpus.words.words())\n",
    "stop = stopwords.words('english')\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "cv_tfidf = TfidfVectorizer(preprocessor=' '.join)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_token(text):\n",
    "    \n",
    "    \n",
    "    text = [text.translate(str.maketrans('', '', string.punctuation))]\n",
    "    text = [word_tokenize(word) for word in text]\n",
    "    text = [item for sublist in text for item in sublist]\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    text = [re.sub(r'http\\S+', '', each) for each in text]\n",
    "    text = [re.sub('[0-9+]', '', each) for each in text]\n",
    "    text = [re.sub('_', '', each) for each in text]\n",
    "    text = [re.sub(\"\\n\",\"\",each) for each in text]\n",
    "    text = [re.sub('/_/g', '', each) for each in text]\n",
    "    text = [re.sub('[^\\u0000-\\u05C0\\u2100-\\u214F]+', '', each) for each in text]\n",
    "    text = [re.sub('[\\u0401\\u0451\\u0410-\\u044f]', '', each) for each in text]\n",
    "    text = [word for word in text if word not in stop]\n",
    "    text = [word.lower() for word in text]\n",
    "    text = [\"\".join(dict.fromkeys(word)) for word in text]\n",
    "\n",
    "    \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068234f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/84/d8w_w6jd1fx_sdq6fsd408cc0000gn/T/ipykernel_77998/4118588387.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#split data into X and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comments' is not defined"
     ]
    }
   ],
   "source": [
    "#split data into X and y\n",
    "\n",
    "X, y = comments['text'], comments['target']\n",
    "print(X.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2082243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#partition data into test data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2929810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create series of all unique comments in the dataset\n",
    "\n",
    "train_corpus = [word for word in X_train]\n",
    "test_corpus = [word for word in X_test]\n",
    "\n",
    "\n",
    "# #tokenize train and test sets \n",
    "\n",
    "train_features = [to_token(comment) for comment in train_corpus]\n",
    "test_features = [to_token(comment) for comment in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18d4d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tfidf vector matrix for train and test sets \n",
    "tfidf = TfidfVectorizer(preprocessor=' '.join)\n",
    "\n",
    "train_tfidf = tfidf.fit_transform(train_features)\n",
    "test_tfidf = tfidf.transform(test_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9852677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use truncated SVD on each tfidf matrix\n",
    "svd = TruncatedSVD(n_components=25, random_state=33)\n",
    "\n",
    "train_svd = svd.fit_transform(train_tfidf)\n",
    "test_svd = svd.transform(test_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cceaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale features\n",
    "\n",
    "scale=StandardScaler()\n",
    "X_train_scaled = scale.fit_transform(train_svd)\n",
    "X_test_scaled = scale.transform(test_svd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "944084f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.817807\n",
       "0    0.182193\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for distribution of labels\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdf3b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create base model\n",
    "lr_basemodel =LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "262c6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train base model\n",
    "lr_basemodel.fit(X_train_scaled,y_train)\n",
    "y_pred_basemodel = lr_basemodel.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92230328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for base model is :  0.9040200038468936\n",
      "ROC AUC score for base model is :  0.5009545579069927\n"
     ]
    }
   ],
   "source": [
    "#get base f1 and roc auc score for model\n",
    "print(\"f1 score for base model is : \" , f1_score(y_test,y_pred_basemodel))\n",
    "print(\"ROC AUC score for base model is : \", roc_auc_score(y_test, y_pred_basemodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "408e7b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 0.5, 1, 10, 15, 20],\n",
       "                         'class_weight': [{0: 0.0, 1: 1.0},\n",
       "                                          {0: 0.0019839679358717435,\n",
       "                                           1: 0.9980160320641283},\n",
       "                                          {0: 0.003967935871743487,\n",
       "                                           1: 0.9960320641282565},\n",
       "                                          {0: 0.0059519038076152305,\n",
       "                                           1: 0.9940480961923848},\n",
       "                                          {0: 0.007935871743486974,\n",
       "                                           1: 0.99206412825...\n",
       "                                           1: 0.9543687374749499},\n",
       "                                          {0: 0.047615230460921844,\n",
       "                                           1: 0.9523847695390781},\n",
       "                                          {0: 0.04959919839679359,\n",
       "                                           1: 0.9504008016032064},\n",
       "                                          {0: 0.05158316633266533,\n",
       "                                           1: 0.9484168336673346},\n",
       "                                          {0: 0.05356713426853708,\n",
       "                                           1: 0.9464328657314629},\n",
       "                                          {0: 0.055551102204408814,\n",
       "                                           1: 0.9444488977955912},\n",
       "                                          {0: 0.05753507014028056,\n",
       "                                           1: 0.9424649298597194}, ...],\n",
       "                         'penalty': ['l2']},\n",
       "             return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "# define model/create instance\n",
    "lr=LogisticRegression()\n",
    "#tuning weight for minority class then weight for majority class will be 1-weight of minority class\n",
    "#Setting the range for class weights\n",
    "weights = np.linspace(0.0,0.99,500)\n",
    "#specifying all hyperparameters with possible values\n",
    "param= {'C': [0.1, 0.5, 1,10,15,20], 'penalty': [ 'l2'],\"class_weight\":[{0:x ,1:1.0 -x} for x in weights]}\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "#Gridsearch for hyperparam tuning\n",
    "model= GridSearchCV(estimator= lr,param_grid=param,scoring=\"roc_auc\",cv=folds,return_train_score=True)\n",
    "#train model to learn relationships between x and y\n",
    "model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a07a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC AUC score:  0.6437623593420919\n",
      "Best hyperparameters:  {'C': 20, 'class_weight': {0: 0.43845691382765534, 1: 0.5615430861723447}, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best ROC AUC score: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76edc8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10,\n",
       "                   class_weight={0: 0.6963727454909819, 1: 0.30362725450901806})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Model with best params\n",
    "lr2=LogisticRegression(class_weight={0: 0.6963727454909819, 1: 0.30362725450901806}\n",
    "                       ,C=10,penalty=\"l2\")\n",
    "lr2.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b50514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix is : \n",
      "\n",
      " [[  42  454]\n",
      " [  84 2271]]\n",
      "\n",
      "\n",
      "ROC-AUC score  test dataset:   0.6428643586055749\n",
      "precision score  test dataset:   0.833394495412844\n",
      "Recall score  test dataset:   0.9643312101910828\n",
      "f1 score  test dataset :   0.8940944881889764\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities on Test and take probability for class 1([:1])\n",
    "y_pred_prob_test = lr2.predict_proba(X_test_scaled)[:, 1]\n",
    "#predict labels on test dataset\n",
    "y_pred_test = lr2.predict(X_test_scaled)\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(f\"confusion Matrix is : \\n\\n\", cm)\n",
    "print(f\"\\n\")\n",
    "\n",
    "# ROC- AUC score\n",
    "print(\"ROC-AUC score  test dataset:  \", roc_auc_score(y_test,y_pred_prob_test))\n",
    "#Precision score\n",
    "print(\"precision score  test dataset:  \", precision_score(y_test,y_pred_test))\n",
    "#Recall Score\n",
    "print(\"Recall score  test dataset:  \", recall_score(y_test,y_pred_test))\n",
    "#f1 score\n",
    "print(\"f1 score  test dataset :  \", f1_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9b4ae08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>Stefano \\nIt would be a much better world if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>\"\\nThey might seem silly to you, but try watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5141</th>\n",
       "      <td>\"\\n\\nI am the person who made the page about \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>Women Preachers \\n\\nWhy do so called Christia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>\"\\n\\n Your Lie(s) About Me \\n\\nYou wrote:\\n\"\"F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "2245   Stefano \\nIt would be a much better world if ...\n",
       "6577  \"\\nThey might seem silly to you, but try watch...\n",
       "5141  \"\\n\\nI am the person who made the page about \"...\n",
       "2758   Women Preachers \\n\\nWhy do so called Christia...\n",
       "4618  \"\\n\\n Your Lie(s) About Me \\n\\nYou wrote:\\n\"\"F..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b990ab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>model_probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>He's notable alright as being a friggen racist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>\"\\n\\n Nonsense sentence \\n\\n\"\"The internationa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.594551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>I didn't say you favored him over me, I said y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>You just make me laugh \\n\\nHAHAHAHAHAHA so yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11398</th>\n",
       "      <td>Silly isn't she? Leabian girl. And you see she...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.683888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "9143   He's notable alright as being a friggen racist...       0   \n",
       "4222   \"\\n\\n Nonsense sentence \\n\\n\"\"The internationa...       0   \n",
       "9579   I didn't say you favored him over me, I said y...       0   \n",
       "2911    You just make me laugh \\n\\nHAHAHAHAHAHA so yo...       0   \n",
       "11398  Silly isn't she? Leabian girl. And you see she...       0   \n",
       "\n",
       "       model_probability  prediction  \n",
       "9143            0.641854           1  \n",
       "4222            0.594551           1  \n",
       "9579            0.623038           1  \n",
       "2911            0.826627           1  \n",
       "11398           0.683888           1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create toxic probability output df\n",
    "test_output = X_test.copy()\n",
    "test_output['target'] = y_test.tolist()\n",
    "test_output[\"model_probability\"] = y_pred_prob_test.tolist()\n",
    "test_output['prediction'] = y_pred_test.tolist()\n",
    "\n",
    "\n",
    "#create toxic probability output for comments that are mislabeled 1\n",
    "miss_0 =  test_output.loc[(test_output['target'] == 0) & (test_output['model_probability']>0.50)]\n",
    "miss_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "148f59fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>model_probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>\"\\n\\n Please stop your disruptive editing. If ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11538</th>\n",
       "      <td>Stop vandalizing the Byrchall High School page...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>Vandalizing ==\\n\\nStop undoing things</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>Vandalism? \\nI have traced this IP \\nhttp://e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>\"== Vandalism ==\\n\\n{{subst:uw-vandalism3|Pres...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "4291   \"\\n\\n Please stop your disruptive editing. If ...       1   \n",
       "11538  Stop vandalizing the Byrchall High School page...       1   \n",
       "12117              Vandalizing ==\\n\\nStop undoing things       1   \n",
       "2537    Vandalism? \\nI have traced this IP \\nhttp://e...       1   \n",
       "7144   \"== Vandalism ==\\n\\n{{subst:uw-vandalism3|Pres...       1   \n",
       "\n",
       "       model_probability  prediction  \n",
       "4291            0.266958           0  \n",
       "11538           0.428810           0  \n",
       "12117           0.467711           0  \n",
       "2537            0.474485           0  \n",
       "7144            0.495347           0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create toxic probability output for comments that are mislabeled 0\n",
    "miss_1 =  test_output.loc[(test_output['target'] == 1) & (test_output['model_probability']<0.50)]\n",
    "miss_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c7766082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save probability score df\n",
    "\n",
    "test_output.to_csv(\"lr_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dacb0ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16983402],\n",
       "       [ 0.80003777],\n",
       "       [-0.11897215],\n",
       "       [ 0.19579705],\n",
       "       [ 0.35809865],\n",
       "       [ 0.07623292],\n",
       "       [ 0.01236455],\n",
       "       [-0.06943656],\n",
       "       [-0.04039331],\n",
       "       [-0.17824921],\n",
       "       [-0.13196447],\n",
       "       [ 0.16098943],\n",
       "       [-0.00094102],\n",
       "       [ 0.09072981],\n",
       "       [-0.00603638],\n",
       "       [ 0.07799175],\n",
       "       [ 0.0391595 ],\n",
       "       [ 0.07885244],\n",
       "       [-0.06261115],\n",
       "       [ 0.08092859],\n",
       "       [ 0.11838693],\n",
       "       [-0.06565282],\n",
       "       [ 0.04632651],\n",
       "       [-0.0262095 ],\n",
       "       [ 0.0554791 ]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " lr2.coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89d0ac14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Vandalism? \\nI have traced this IP \\nhttp://en.wikipedia.org/wiki/User_talk:78.55.58.71 but I had not found the slightest hint on vandalism. Why do you block users on false reasons?  92.230.85.188  '"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_1.iloc[3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8856798e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' You just make me laugh \\n\\nHAHAHAHAHAHA so you are some aussie bitch hiding behind a computer and changing what i write, im half abo half lebo so i am the truth u cannot face but your girlfriend faces every night ;)'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_0.iloc[3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3304183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
